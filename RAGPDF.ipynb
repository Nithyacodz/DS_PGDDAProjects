{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1d6b20f-b072-40bb-8438-a4e38bb1416b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "genai.configure(api_key=\"AIzaSyA32_IUqgUW-_5astz4Z6PO82MO_egC7AY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e01376c-91d0-4cf1-8c6d-fe29b68e174b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import textwrap\n",
    "\n",
    "import google.generativeai as genai\n",
    "\n",
    "from IPython.display import display\n",
    "from IPython.display import Markdown\n",
    "\n",
    "def to_markdown(text):\n",
    "  text = text.replace('•', '  *')\n",
    "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd5a1038-9413-4e93-a3e5-f83ddee16b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
    "data = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "all_splits = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6dca223d-17ed-41d7-aa48-40a89ad710b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "local_embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=all_splits, embedding=local_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d253c8f-ab8e-4cc2-8538-6f9865a3ffb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What are the approaches to Task Decomposition?\"\n",
    "docs = vectorstore.similarity_search(question)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aed839d-4ff8-4076-b704-84150277d5c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d9af09f-0eba-4dd8-b2d6-8a2bf776fbb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8762aac0-08ee-4df9-8c25-adef15a7eafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "model = ChatOllama(\n",
    "    model=\"llama3.1:8b\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9e1073b-7bb9-4b07-8fbf-c35bf3be9453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What a fantastic idea! Here's a simulated rap battle between Stephen Colbert and John Oliver:\n",
      "\n",
      "**The Scene:** A dark, crowded nightclub. The air is electric with anticipation as two of the sharpest tongues in comedy take to the stage. In the blue corner, we have Stephen Colbert, dressed in his signature \"Lambert Strether\" suit. In the red corner, we have John Oliver, sporting a confident smirk.\n",
      "\n",
      "**Round 1: Stephen Colbert**\n",
      "\n",
      "Yo, I'm the King of Late Night, the one and only\n",
      "My humor's sharp as a knife, don't be gettin' lonely\n",
      "I've got truth on my side, it's like a trusty friend\n",
      "While you're over there, makin' jokes that offend\n",
      "\n",
      "**Round 1: John Oliver**\n",
      "\n",
      "Hold up, Stevie, let me take the stage\n",
      "Your humor's stale as yesterday's Trump age\n",
      "You claim to be a patriot, but really you're just whiny\n",
      "Tryin' to out-criticize critics with your sassy, scripted comedy\n",
      "\n",
      "**Round 2: Stephen Colbert**\n",
      "\n",
      "My script is tight, my delivery's on point\n",
      "I've got the facts straight, ain't nobody gonna get hurt by my joint\n",
      "You may have a show on HBO, but I'm still the best\n",
      "When it comes to satire, no one beats me, I'm the king of the nest\n",
      "\n",
      "**Round 2: John Oliver**\n",
      "\n",
      "Best? You're the best at makin' people laugh at your own jokes?\n",
      "My show's got depth, mine's got bite, yours is just a joke-y smoke\n",
      "I tackle real issues with facts and wit and flair\n",
      "You stick to Trump, but I'm goin' after the system, like I care\n",
      "\n",
      "**Round 3: Stephen Colbert**\n",
      "\n",
      "You may have won awards, but I've still got the charm\n",
      "My show's the most popular, it don't matter who's doin' harm\n",
      "I'm the host with the most, no debate there\n",
      "You're just a one-man show tryin' to steal my care\n",
      "\n",
      "**Round 3: John Oliver**\n",
      "\n",
      "Charm? You mean like that time you dressed up as George W.?\n",
      "That was cute, but now I'm here and I'm not impressed, kid.\n",
      "My show's got heart, mine's got brains\n",
      "You may have won awards, but I've still got the game in plain sight\n",
      "\n",
      "**The Verdict:** It's a close call, folks! Both Stephen Colbert and John Oliver brought their A-game to this rap battle. In the end, it's up to you to decide who won...\n"
     ]
    }
   ],
   "source": [
    "response_message = model.invoke(\n",
    "    \"Simulate a rap battle between Stephen Colbert and John Oliver\"\n",
    ")\n",
    "\n",
    "print(response_message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0e86a43-60bc-4dbc-9560-37d27ff4a7a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The main themes in these retrieved documents are:\\n\\n1. **AI Planning and Problem-Solving**: A focus on developing autonomous agents that can plan and execute complex tasks by breaking them down into smaller subgoals.\\n2. **Tree-based Reasoning**: An exploration of multiple reasoning possibilities using a tree structure, which allows for Breadth-First Search (BFS) or Depth-First Search (DFS) strategies to evaluate states.\\n3. **Human-AI Collaboration**: A discussion on how human-in-the-loop approaches, such as prompting classifiers or majority voting, can be used to evaluate and refine AI-generated thoughts and actions.\\n\\nThe documents also touch on the importance of:\\n\\n* **Task Decomposition**: Breaking down complex tasks into manageable subgoals\\n* **Reflection and Refinement**: Learning from mistakes and refining past actions for future improvements\\n\\nOverall, these themes suggest a focus on developing more efficient and effective AI planning and problem-solving strategies that leverage human-AI collaboration and tree-based reasoning.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"Summarize the main themes in these retrieved docs: {docs}\"\n",
    ")\n",
    "\n",
    "\n",
    "# Convert loaded documents into strings by concatenating their content\n",
    "# and ignoring metadata\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "chain = {\"docs\": format_docs} | prompt | model | StrOutputParser()\n",
    "\n",
    "question = \"What are the approaches to Task Decomposition?\"\n",
    "\n",
    "docs = vectorstore.similarity_search(question)\n",
    "\n",
    "chain.invoke(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aff9f927-b86c-4580-8a47-13d5e3d46364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"According to the context, Task Decomposition involves breaking down large tasks into smaller, manageable subgoals. The text mentions no specific approaches to Task Decomposition, so I don't know. However, it does mention that this is a component of Planning in a LLM-powered autonomous agent system.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "RAG_TEMPLATE = \"\"\"\n",
    "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Answer the following question:\n",
    "\n",
    "{question}\"\"\"\n",
    "\n",
    "rag_prompt = ChatPromptTemplate.from_template(RAG_TEMPLATE)\n",
    "\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(context=lambda input: format_docs(input[\"context\"]))\n",
    "    | rag_prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "question = \"What are the approaches to Task Decomposition?\"\n",
    "\n",
    "docs = vectorstore.similarity_search(question)\n",
    "\n",
    "# Run\n",
    "chain.invoke({\"context\": docs, \"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2cf23352-a844-4420-b595-15a3b11340a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "qa_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | rag_prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b12d2e47-48f3-4888-9138-2d9cb74a99a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The context mentions that there are two approaches to Task Decomposition: Subgoal and decomposition. It's not clear what this approach entails, but it seems to be one of the methods used in Planning Component One.\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What are the approaches to Task Decomposition?\"\n",
    "\n",
    "qa_chain.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af62b3ab-dacc-4d3a-9383-b423a2180ae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The agent system is a LLM-powered autonomous system that combines the large language model (LLM) with several key components, such as memory, planning, and reflection mechanisms. This enables agents to behave conditioned on past experience and interact with other agents. The design aims to make the LLM a powerful general problem solver.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What are agent system overview?\"\n",
    "\n",
    "qa_chain.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ffab980-5f78-4574-9687-0c9a35bf3bb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There are several types of memory, including Explicit/Declarative memory (facts and events) and Implicit/Procedural memory (skills and routines). Additionally, there is Short-Term Memory (STM) or Working Memory (stores information for a short time) and Long-Term Memory (LTM), which can store information for a long time.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What are the types of memory?\"\n",
    "\n",
    "qa_chain.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15aeb441-92f7-4a98-8cc2-6ba8a175f464",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710022d3-4971-4467-ba91-46e796c852ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ebdaeb-687f-4a7b-bfd2-7dd109421b92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
